{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOpbzhoiLatk"
      },
      "source": [
        "## Installation and Setup of YoloV6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-UbdAg3-_vU"
      },
      "outputs": [],
      "source": [
        "#pyTorch dependency to check GPU Availability\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm3l4h3DGcgn",
        "outputId": "91b22ff2-ad14-4c10-9b51-7991ee473752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HqAMD_eGh35",
        "outputId": "ea4df6a9-937f-425f-eb7a-fa298a723224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Oct 16 01:35:25 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8    10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9dp-7IyIYI6",
        "outputId": "4138eb39-5268-4a11-b1f8-80efda7c2a27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'YOLOv6'...\n",
            "remote: Enumerating objects: 3785, done.\u001b[K\n",
            "remote: Counting objects: 100% (1665/1665), done.\u001b[K\n",
            "remote: Compressing objects: 100% (291/291), done.\u001b[K\n",
            "remote: Total 3785 (delta 1473), reused 1375 (delta 1374), pack-reused 2120\u001b[K\n",
            "Receiving objects: 100% (3785/3785), 47.11 MiB | 29.41 MiB/s, done.\n",
            "Resolving deltas: 100% (2305/2305), done.\n"
          ]
        }
      ],
      "source": [
        "#Importing Yolvov6\n",
        "!git clone https://github.com/meituan/YOLOv6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_n_NwuwImNS",
        "outputId": "546c6088-a2f0-4dcc-bd32-dd4d9a2c5dfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/YOLOv6\n"
          ]
        }
      ],
      "source": [
        "%cd YOLOv6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQLHiuHKIrB0",
        "outputId": "2585bf98-0937-4b89-9a4f-51d1cc24ea0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.15.2+cu118)\n",
            "Collecting numpy>=1.24.0 (from -r requirements.txt (line 6))\n",
            "  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.8.0.76)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.11.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.66.1)\n",
            "Collecting addict>=2.4.0 (from -r requirements.txt (line 11))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: tensorboard>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.13.0)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.0.7)\n",
            "Collecting onnx>=1.10.0 (from -r requirements.txt (line 14))\n",
            "  Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx-simplifier>=0.3.6 (from -r requirements.txt (line 15))\n",
            "  Downloading onnx_simplifier-0.4.33-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting thop (from -r requirements.txt (line 16))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r requirements.txt (line 4)) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r requirements.txt (line 4)) (17.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (9.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.41.2)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0->-r requirements.txt (line 13)) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (13.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.2.2)\n",
            "Installing collected packages: addict, numpy, onnx, onnx-simplifier, thop\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.1 which is incompatible.\n",
            "tensorflow 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.26.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed addict-2.4.0 numpy-1.26.1 onnx-1.14.1 onnx-simplifier-0.4.33 thop-0.1.1.post2209072238\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1JH5D6BlIySM",
        "outputId": "ad8491a7-46aa-4d70-9174-c0a954941e73"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/YOLOv6'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku3We8RiL913"
      },
      "source": [
        "## Importing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozD8MoF2LSha"
      },
      "outputs": [],
      "source": [
        "#Importing from Github\n",
        "\"\"\"%cd /content\n",
        "!curl -L <Github Link> > data_yolov6.zip; unzip data_yolov6.zip; rm data_yolov6.zip\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h09-B_gdg5c_",
        "outputId": "7c4cb0a2-dc9d-4b2d-84f5-c83df6f2650c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n",
            "Extracted Files= ['.config', 'dataset.yaml', 'YOLOv6', 'images', 'labels', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "#Mount Google Drive\n",
        "drive.mount(\"/drive\",force_remount=True)\n",
        "#File Path\n",
        "zip_file_path=\"/drive/My Drive/Content1/data_yolov6.zip\"\n",
        "destination_folder=\"/content/\"\n",
        "\n",
        "#Unzipping the files\n",
        "import zipfile\n",
        "with zipfile.ZipFile(zip_file_path,\"r\") as zip_ref:\n",
        "  zip_ref.extractall(destination_folder)\n",
        "\n",
        "#Listing the extracted files\n",
        "import os\n",
        "extracted_files=os.listdir(destination_folder)\n",
        "print(\"Extracted Files=\",extracted_files)\n",
        "\n",
        "#Unmounting\n",
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x134df4BTuW1"
      },
      "source": [
        "## Training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0wTMXgNTsgs",
        "outputId": "f227c558-08e4-4d0f-a479-6cc6c5225698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/YOLOv6\n",
            "--2023-10-16 01:36:53--  https://github.com/meituan/YOLOv6/releases/download/0.1.0/yolov6s.pt\n",
            "Resolving github.com (github.com)... 20.29.134.23\n",
            "Connecting to github.com (github.com)|20.29.134.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/501076075/7af0d5c3-a8e5-456e-ae8c-29b7fc22753e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231016%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231016T013653Z&X-Amz-Expires=300&X-Amz-Signature=3fcbfdfbb367c9d7b400912affb8b283e269ed0c6ecc431cc197d547f46c8769&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=501076075&response-content-disposition=attachment%3B%20filename%3Dyolov6s.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-10-16 01:36:53--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/501076075/7af0d5c3-a8e5-456e-ae8c-29b7fc22753e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231016%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231016T013653Z&X-Amz-Expires=300&X-Amz-Signature=3fcbfdfbb367c9d7b400912affb8b283e269ed0c6ecc431cc197d547f46c8769&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=501076075&response-content-disposition=attachment%3B%20filename%3Dyolov6s.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38102844 (36M) [application/octet-stream]\n",
            "Saving to: ‘yolov6s.pt’\n",
            "\n",
            "yolov6s.pt          100%[===================>]  36.34M  68.3MB/s    in 0.5s    \n",
            "\n",
            "2023-10-16 01:36:54 (68.3 MB/s) - ‘yolov6s.pt’ saved [38102844/38102844]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Downloading a Pre-trained Model\n",
        "%cd /content/YOLOv6\n",
        "!wget https://github.com/meituan/YOLOv6/releases/download/0.1.0/yolov6s.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IR6ZVHhDKnEP"
      },
      "outputs": [],
      "source": [
        "# %cd /content/YOLOv6\n",
        "# !wget https://github.com/meituan/YOLOv6/releases/tag/0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysaRfFp0LdUg",
        "outputId": "35c2778c-dc3b-4af0-bcde-25258655776c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/YOLOv6\n",
            "--2023-10-16 01:51:37--  https://github.com/meituan/YOLOv6/releases/download/0.3.0/yolov6s.pt\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/501076075/97258e10-d656-4c3c-8046-e08f2628fcc6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231016%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231016T015137Z&X-Amz-Expires=300&X-Amz-Signature=3965150e259153c566e8a596b21e4adfba36e4f29d796657aaa5932c4f83f2e7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=501076075&response-content-disposition=attachment%3B%20filename%3Dyolov6s.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-10-16 01:51:37--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/501076075/97258e10-d656-4c3c-8046-e08f2628fcc6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231016%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231016T015137Z&X-Amz-Expires=300&X-Amz-Signature=3965150e259153c566e8a596b21e4adfba36e4f29d796657aaa5932c4f83f2e7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=501076075&response-content-disposition=attachment%3B%20filename%3Dyolov6s.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40766950 (39M) [application/octet-stream]\n",
            "Saving to: ‘yolov6s.pt.1’\n",
            "\n",
            "yolov6s.pt.1        100%[===================>]  38.88M  70.5MB/s    in 0.6s    \n",
            "\n",
            "2023-10-16 01:51:38 (70.5 MB/s) - ‘yolov6s.pt.1’ saved [40766950/40766950]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd /content/YOLOv6\n",
        "!wget https://github.com/meituan/YOLOv6/releases/download/0.3.0/yolov6s.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_OxRZJJVZix",
        "outputId": "1bd1a2d9-5fde-4a17-9a98-c729ebb32c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'YOLOv6'\n",
            "/content/YOLOv6\n",
            "2023-10-16 01:51:45.537094: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-16 01:51:46.438347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using 1 GPU for training... \n",
            "training args are: Namespace(data_path='/content/dataset.yaml', conf_file='configs/yolov6s_finetune.py', img_size=640, rect=False, batch_size=16, epochs=50, workers=8, device='0', eval_interval=20, eval_final_only=False, heavy_eval_range=50, check_images=False, check_labels=False, output_dir='./runs/train', name='exp', dist_url='env://', gpu_count=0, local_rank=-1, resume=False, write_trainbatch_tb=False, stop_aug_last_n_epoch=15, save_ckpt_on_last_n_epoch=-1, distill=False, distill_feat=False, quant=False, calib=False, teacher_model_path=None, temperature=20, fuse_ab=False, bs_per_gpu=32, specific_shape=False, height=None, width=None, cache_ram=False, rank=-1, world_size=1, save_dir='runs/train/exp')\n",
            "\n",
            "checkpoint yolov6s.pt not exist, try to downloaded it from github.\n",
            "downloading url is: https://github.com/meituan/YOLOv6/releases/download/0.4.0/yolov6s.pt, pealse make sure the version of the downloading model is correspoing to the code version!\n",
            "checkpoint yolov6s.pt downloaded and saved\n",
            "Loading state_dict from weights/yolov6s.pt for fine-tuning...\n",
            "Model: Model(\n",
            "  (backbone): EfficientRep(\n",
            "    (stem): RepVGGBlock(\n",
            "      (nonlinearity): ReLU(inplace=True)\n",
            "      (se): Identity()\n",
            "      (rbr_dense): ConvModule(\n",
            "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (rbr_1x1): ConvModule(\n",
            "        (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_2): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_3): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_4): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (2): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (3): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (4): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ERBlock_5): Sequential(\n",
            "      (0): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): RepBlock(\n",
            "        (conv1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (block): Sequential(\n",
            "          (0): RepVGGBlock(\n",
            "            (nonlinearity): ReLU(inplace=True)\n",
            "            (se): Identity()\n",
            "            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (rbr_dense): ConvModule(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (rbr_1x1): ConvModule(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): SimCSPSPPF(\n",
            "        (cspsppf): CSPSPPFModule(\n",
            "          (cv1): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv2): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv3): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv4): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "          (cv5): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv6): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "          (cv7): ConvBNReLU(\n",
            "            (block): ConvModule(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): ReLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (neck): RepBiFPANNeck(\n",
            "    (reduce_layer0): ConvBNReLU(\n",
            "      (block): ConvModule(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Bifusion0): BiFusion(\n",
            "      (cv1): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (cv2): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (cv3): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (upsample): Transpose(\n",
            "        (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "      )\n",
            "      (downsample): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_p4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_layer1): ConvBNReLU(\n",
            "      (block): ConvModule(\n",
            "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Bifusion1): BiFusion(\n",
            "      (cv1): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (cv2): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (cv3): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (upsample): Transpose(\n",
            "        (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "      )\n",
            "      (downsample): ConvBNReLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (Rep_p3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (downsample2): ConvBNReLU(\n",
            "      (block): ConvModule(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_n3): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (downsample1): ConvBNReLU(\n",
            "      (block): ConvModule(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (Rep_n4): RepBlock(\n",
            "      (conv1): RepVGGBlock(\n",
            "        (nonlinearity): ReLU(inplace=True)\n",
            "        (se): Identity()\n",
            "        (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (rbr_dense): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (rbr_1x1): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (block): Sequential(\n",
            "        (0): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): RepVGGBlock(\n",
            "          (nonlinearity): ReLU(inplace=True)\n",
            "          (se): Identity()\n",
            "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (rbr_dense): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (rbr_1x1): ConvModule(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (detect): Detect(\n",
            "    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (stems): ModuleList(\n",
            "      (0): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cls_convs): ModuleList(\n",
            "      (0): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): ConvBNSiLU(\n",
            "        (block): ConvModule(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cls_preds): ModuleList(\n",
            "      (0): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds): ModuleList(\n",
            "      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "img record infomation path is:../images/.train_cache.json\n",
            "Train: Checking formats of images with 2 process(es): \n",
            "0 image(s) corrupted: 100% 1101/1101 [00:00<00:00, 2971.05it/s]\n",
            "Train: Checking formats of labels with 2 process(es): \n",
            "1101 label(s) found, 0 label(s) missing, 0 label(s) empty, 0 invalid label files: 100% 1101/1101 [00:00<00:00, 2937.40it/s]\n",
            "Train: Final numbers of valid images: 1101/ labels: 1101. \n",
            "1.0s for dataset initialization.\n",
            "img record infomation path is:../images/.val_cache.json\n",
            "Val: Checking formats of images with 2 process(es): \n",
            "0 image(s) corrupted: 100% 309/309 [00:00<00:00, 1380.68it/s]\n",
            "Val: Checking formats of labels with 2 process(es): \n",
            "309 label(s) found, 0 label(s) missing, 0 label(s) empty, 0 invalid label files: 100% 309/309 [00:00<00:00, 1130.32it/s]\n",
            "Convert to COCO format\n",
            "100% 309/309 [00:00<00:00, 23553.66it/s]\n",
            "Convert to COCO format finished. Resutls saved in ../annotations/instances_val.json\n",
            "Val: Final numbers of valid images: 309/ labels: 309. \n",
            "1.0s for dataset initialization.\n",
            "Training start...\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      0/49     0.0016    0.4093         0     2.702: 100%|██████████| 69/69 [01:22<00:00,  1.19s/it]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      1/49     0.0016    0.3707         0     1.673: 100%|██████████| 69/69 [01:08<00:00,  1.01it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      2/49   0.001599    0.3683         0      1.18: 100%|██████████| 69/69 [01:08<00:00,  1.01it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:12<00:00,  1.23s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=1.19s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.52s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.65s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.134\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.101\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.360\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.153\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.662\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.931\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 2 | mAP@0.5: 0.1343622195346776 | mAP@0.50:0.95: 0.08415877424034957\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      3/49   0.001594    0.3531         0      1.01: 100%|██████████| 69/69 [01:05<00:00,  1.05it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      4/49   0.001588     0.345         0    0.8639: 100%|██████████| 69/69 [01:05<00:00,  1.06it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      5/49   0.001578     0.353         0    0.8074: 100%|██████████| 69/69 [01:06<00:00,  1.03it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:12<00:00,  1.30s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.73s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=3.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=1.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.168\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.297\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.259\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.255\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.689\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 5 | mAP@0.5: 0.2847557035837869 | mAP@0.50:0.95: 0.16846384968862013\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      6/49   0.001566    0.3492         0    0.7488: 100%|██████████| 69/69 [01:04<00:00,  1.07it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      7/49   0.001551    0.3633         0    0.7304: 100%|██████████| 69/69 [01:05<00:00,  1.05it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      8/49   0.001533    0.3632         0    0.7171: 100%|██████████| 69/69 [01:05<00:00,  1.05it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:12<00:00,  1.24s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.71s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.56s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.124\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.024\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.227\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.638\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 8 | mAP@0.5: 0.28832102902780354 | mAP@0.50:0.95: 0.14553348214406667\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "      9/49   0.001513    0.3589         0    0.6966: 100%|██████████| 69/69 [01:06<00:00,  1.03it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     10/49    0.00149    0.3336         0    0.6768: 100%|██████████| 69/69 [01:06<00:00,  1.04it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     11/49   0.001466    0.3461         0    0.6822: 100%|██████████| 69/69 [01:05<00:00,  1.06it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:11<00:00,  1.16s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.37s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.51s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.41s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.191\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.213\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.069\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 11 | mAP@0.5: 0.3094216683554262 | mAP@0.50:0.95: 0.19140030542689399\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     12/49   0.001438    0.3397         0    0.6563: 100%|██████████| 69/69 [01:05<00:00,  1.06it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     13/49   0.001409    0.3333         0     0.653: 100%|██████████| 69/69 [01:06<00:00,  1.03it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     14/49   0.001378    0.3419         0     0.651: 100%|██████████| 69/69 [01:05<00:00,  1.05it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:10<00:00,  1.01s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.35s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.68s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.321\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.258\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.415\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.050\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 14 | mAP@0.5: 0.321289910838178 | mAP@0.50:0.95: 0.15828987170543393\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     15/49   0.001345    0.3309         0     0.634: 100%|██████████| 69/69 [01:05<00:00,  1.06it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     16/49    0.00131    0.3316         0    0.6313: 100%|██████████| 69/69 [01:06<00:00,  1.04it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     17/49   0.001273    0.3306         0    0.6219: 100%|██████████| 69/69 [01:05<00:00,  1.05it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:08<00:00,  1.22it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.64s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.65s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.46s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.191\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.297\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.337\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 17 | mAP@0.5: 0.3447356065437489 | mAP@0.50:0.95: 0.19122349937935487\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     18/49   0.001235    0.3275         0     0.619: 100%|██████████| 69/69 [01:03<00:00,  1.08it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     19/49   0.001196    0.3195         0    0.6114: 100%|██████████| 69/69 [01:05<00:00,  1.05it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     20/49   0.001155    0.3049         0     0.595: 100%|██████████| 69/69 [01:06<00:00,  1.03it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:09<00:00,  1.09it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.56s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.55s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.31s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.335\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.256\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.022\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 20 | mAP@0.5: 0.33485039479849993 | mAP@0.50:0.95: 0.19615458192944338\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     21/49   0.001114     0.311         0    0.6096: 100%|██████████| 69/69 [01:04<00:00,  1.06it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     22/49   0.001071    0.3074         0    0.5988: 100%|██████████| 69/69 [01:05<00:00,  1.05it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     23/49   0.001028    0.2963         0    0.5964: 100%|██████████| 69/69 [01:05<00:00,  1.05it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:10<00:00,  1.08s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.40s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.13s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.33s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.375\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.261\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.324\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.231\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.385\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 23 | mAP@0.5: 0.3749546600047465 | mAP@0.50:0.95: 0.22333522715492712\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     24/49  0.0009842    0.2977         0    0.5838: 100%|██████████| 69/69 [01:07<00:00,  1.02it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     25/49  0.0009402    0.2969         0    0.5859: 100%|██████████| 69/69 [01:06<00:00,  1.04it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     26/49   0.000896    0.2997         0    0.5875: 100%|██████████| 69/69 [01:04<00:00,  1.06it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:10<00:00,  1.03s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.44s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.90s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.26s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.213\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.383\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 26 | mAP@0.5: 0.38391187571055696 | mAP@0.50:0.95: 0.20573443068048988\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     27/49  0.0008518    0.2893         0    0.5727: 100%|██████████| 69/69 [01:04<00:00,  1.07it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     28/49  0.0008078    0.2892         0    0.5756: 100%|██████████| 69/69 [01:04<00:00,  1.07it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     29/49  0.0007641    0.2898         0     0.573: 100%|██████████| 69/69 [01:04<00:00,  1.07it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:09<00:00,  1.08it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.47s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.89s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.25s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.208\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.380\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.230\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.406\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 29 | mAP@0.5: 0.38045117137269496 | mAP@0.50:0.95: 0.2081846038173617\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     30/49  0.0007209    0.2851         0    0.5693: 100%|██████████| 69/69 [01:03<00:00,  1.09it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     31/49  0.0006785    0.2886         0    0.5668: 100%|██████████| 69/69 [01:05<00:00,  1.06it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     32/49  0.0006368    0.2836         0    0.5649: 100%|██████████| 69/69 [01:05<00:00,  1.06it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:08<00:00,  1.25it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.21s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.37s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.233\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.236\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.386\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.376\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 32 | mAP@0.5: 0.39100408149145643 | mAP@0.50:0.95: 0.21571693064334943\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     33/49  0.0005963    0.2813         0    0.5701: 100%|██████████| 69/69 [01:04<00:00,  1.07it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     34/49  0.0005568    0.2806         0    0.5585: 100%|██████████| 69/69 [01:02<00:00,  1.10it/s]\n",
            "img record infomation path is:../images/.train_cache.json\n",
            "Train: Final numbers of valid images: 1101/ labels: 1101. \n",
            "0.1s for dataset initialization.\n",
            "img record infomation path is:../images/.val_cache.json\n",
            "Convert to COCO format\n",
            "100% 309/309 [00:00<00:00, 53203.61it/s]\n",
            "Convert to COCO format finished. Resutls saved in ../annotations/instances_val.json\n",
            "Val: Final numbers of valid images: 309/ labels: 309. \n",
            "0.2s for dataset initialization.\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     35/49  0.0005188    0.2488         0    0.5262: 100%|██████████| 69/69 [00:28<00:00,  2.43it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:06<00:00,  1.54it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.50s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.84s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.26s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.217\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.221\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.294\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.377\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 35 | mAP@0.5: 0.3758869394766793 | mAP@0.50:0.95: 0.20571172155303347\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     36/49  0.0004822    0.2484         0    0.5262: 100%|██████████| 69/69 [00:26<00:00,  2.63it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     37/49  0.0004473    0.2465         0    0.5192: 100%|██████████| 69/69 [00:26<00:00,  2.57it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     38/49  0.0004141    0.2501         0    0.5186: 100%|██████████| 69/69 [00:26<00:00,  2.56it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:06<00:00,  1.44it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.40s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.50s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.365\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.205\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.215\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.390\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 38 | mAP@0.5: 0.3650951372129438 | mAP@0.50:0.95: 0.1980848354233165\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     39/49  0.0003828      0.25         0    0.5214: 100%|██████████| 69/69 [00:26<00:00,  2.60it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     40/49  0.0003536    0.2455         0    0.5166: 100%|██████████| 69/69 [00:26<00:00,  2.58it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     41/49  0.0003265    0.2492         0    0.5169: 100%|██████████| 69/69 [00:26<00:00,  2.59it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:06<00:00,  1.43it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.15s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.44s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.48s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.140\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.382\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 41 | mAP@0.5: 0.36963469526960724 | mAP@0.50:0.95: 0.1951639067825217\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     42/49  0.0003016    0.2376         0    0.5082: 100%|██████████| 69/69 [00:26<00:00,  2.59it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     43/49  0.0002791    0.2414         0    0.5115: 100%|██████████| 69/69 [00:26<00:00,  2.62it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     44/49   0.000259    0.2408         0    0.5088: 100%|██████████| 69/69 [00:26<00:00,  2.62it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:07<00:00,  1.39it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.57s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.54s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.259\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.313\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.419\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.404\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 44 | mAP@0.5: 0.37428510264348763 | mAP@0.50:0.95: 0.2203597170677656\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     45/49  0.0002414    0.2481         0    0.5133: 100%|██████████| 69/69 [00:27<00:00,  2.53it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     46/49  0.0002265    0.2436         0    0.5107: 100%|██████████| 69/69 [00:27<00:00,  2.53it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     47/49  0.0002141    0.2378         0    0.5058: 100%|██████████| 69/69 [00:26<00:00,  2.60it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:07<00:00,  1.31it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.19s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.26s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.358\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.234\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.215\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.377\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 47 | mAP@0.5: 0.3581632747157688 | mAP@0.50:0.95: 0.20223589596767047\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     48/49  0.0002045    0.2387         0    0.5093: 100%|██████████| 69/69 [00:26<00:00,  2.57it/s]\n",
            "\n",
            "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
            "     49/49  0.0001976    0.2402         0    0.5126: 100%|██████████| 69/69 [00:26<00:00,  2.58it/s]\n",
            "Inferencing model in train datasets.: 100%|█████████████████████████| 10/10 [00:06<00:00,  1.49it/s]\n",
            "\n",
            "Evaluating speed.\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/train/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.65s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.67s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.29s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.217\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.369\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.251\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.232\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Results saved to runs/train/exp\n",
            "Epoch: 49 | mAP@0.5: 0.36896691469983284 | mAP@0.50:0.95: 0.2169801009357209\n",
            "\n",
            "Training completed in 0.863 hours.\n"
          ]
        }
      ],
      "source": [
        "#Training Process\n",
        "%cd YOLOv6\n",
        "!python tools/train.py --batch 16 --conf configs/yolov6s_finetune.py --data /content/dataset.yaml --device 0 --epochs 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-yGd4tHk1p9"
      },
      "source": [
        "## Evaluation/Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwQGVWfwkVgO",
        "outputId": "ecc6a13c-5b29-460f-8a7d-b063b221a780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(data='/content/dataset.yaml', weights='runs/train/exp/weights/best_ckpt.pt', batch_size=32, img_size=640, conf_thres=0.03, iou_thres=0.65, task='val', device='0', half=False, save_dir='runs/val/', name='exp', shrink_size=0, infer_on_rect=True, reproduce_640_eval=False, eval_config_file='./configs/experiment/eval_640_repro.py', do_coco_metric=True, do_pr_metric=False, plot_curve=True, plot_confusion_matrix=False, verbose=False, config_file='', specific_shape=False, height=None, width=None)\n",
            "Loading checkpoint from runs/train/exp/weights/best_ckpt.pt\n",
            "\n",
            "Fusing model...\n",
            "Switch model to deploy modality.\n",
            "Model Summary: Params: 18.50M, Gflops: 45.17\n",
            "img record infomation path is:../images/.val_cache.json\n",
            "Val: Checking formats of labels with 2 process(es): \n",
            "309 label(s) found, 0 label(s) missing, 0 label(s) empty, 0 invalid label files: 100% 309/309 [00:00<00:00, 3057.95it/s]\n",
            "Convert to COCO format\n",
            "100% 309/309 [00:00<00:00, 129409.88it/s]\n",
            "Convert to COCO format finished. Resutls saved in ../annotations/instances_val.json\n",
            "Val: Final numbers of valid images: 309/ labels: 309. \n",
            "0.3s for dataset initialization.\n",
            "Inferencing model in val datasets.: 100%|███████████████████████████| 10/10 [00:10<00:00,  1.02s/it]\n",
            "\n",
            "Evaluating speed.\n",
            "Average pre-process time: 0.11 ms\n",
            "Average inference time: 5.78 ms\n",
            "Average NMS time: 2.47 ms\n",
            "\n",
            "Evaluating mAP by pycocotools.\n",
            "Saving runs/val/exp/predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.44s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.33s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.231\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.385\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "Results saved to runs/val/exp\n"
          ]
        }
      ],
      "source": [
        "!python tools/eval.py --data /content/dataset.yaml --weights runs/train/exp/weights/best_ckpt.pt --device 0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
